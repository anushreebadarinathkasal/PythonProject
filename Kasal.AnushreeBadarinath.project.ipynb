{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project\n",
    "### __Input:__\n",
    "#### *User Inputs the stock symbol from the displayed list*\n",
    "### __Output:__\n",
    "#### *Displays the list of Most Actives, Gainers, Losers Stock names*\n",
    "#### *Creates stocks.csv with open,close,volume,marketcap information*\n",
    "#### *Displays the stock information requested by the user*\n",
    "### __Algorithm:__\n",
    "#### *The program parses the information from the hotstocks url website and creates the dictionary of the stocks and display*\n",
    "#### *The program uses Ticker Symbol to query the Yahoo finance website and get all the stock information, Creates CSV*\n",
    "#### *User should enter stock symbol from the displayed list*\n",
    "#### *Displays the stock Information for the user entered Symbol*\n",
    "### __Instructions to Execute:__ \n",
    "#### *Click on the below cell and execute run button.Enter the symbol of the stock interested in to get the information displayed*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a program to scrape data from the https://money.cnn.com/data/hotstocks/ for a class project\n",
      "Which stock are you interested in:\n",
      " \n",
      "Most Actives:\n",
      "GE General Electric Co\n",
      "BAC Bank of America Corp\n",
      "T AT&T Inc\n",
      "AMD Advanced Micro Devices Inc\n",
      "F Ford Motor Co\n",
      "MSFT Microsoft Corp\n",
      "AAPL Apple Inc\n",
      "BMY Bristol-Myers Squibb Co\n",
      "FCX Freeport-McMoRan Inc\n",
      "HPQ HP Inc\n",
      " \n",
      "Gainers:\n",
      "NRG NRG Energy Inc\n",
      "HPQ HP Inc\n",
      "CF CF Industries Holdings Inc\n",
      "DXC DXC Technology Co\n",
      "CME CME Group Inc\n",
      "CRM Salesforce.Com Inc\n",
      "DRI Darden Restaurants Inc\n",
      "ICE Intercontinental Exchange Inc\n",
      "VRTX Vertex Pharmaceuticals Inc\n",
      "ATVI Activision Blizzard Inc\n",
      " \n",
      "Losers:\n",
      "APA Apache Corp\n",
      "FTI TechnipFMC PLC\n",
      "DVN Devon Energy Corp\n",
      "KSS Kohls Corp\n",
      "HP Helmerich and Payne Inc\n",
      "NBL Noble Energy Inc\n",
      "URI United Rentals Inc\n",
      "HBI HanesBrands Inc\n",
      "LYB LyondellBasell Industries NV\n",
      "EOG EOG Resources Inc\n",
      "\n",
      "User Inputs:APA\n",
      "\n",
      "The data for APA Apache Corp is the following:\n",
      "\n",
      "APA Apache Corp\n",
      "OPEN : 22.78\n",
      "PREV_CLOSE : 23.22\n",
      "VOLUME : 3,198,120\n",
      "MARKET_CAP : 8.378B\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import csv\n",
    "\n",
    "myurl='https://money.cnn.com/data/hotstocks/'  #Input Website to scrape the data of most active,gainers,losers stocks\n",
    "\n",
    "\n",
    "try:\n",
    "    hotstocks_handle = requests.get(myurl)    #Request Made to the website\n",
    "    hotstocks_text = hotstocks_handle.text    #Text from the website\n",
    "    soup = BeautifulSoup(hotstocks_text, 'html.parser') #Use soup as html Parser\n",
    "    active_s_dict={}                          #Create Empty active stocks dict\n",
    "    gainers_s_dict={}                         #Create Gainers active stocks dict\n",
    "    losers_s_dict={}                          #Create losers active stocks dict\n",
    "    i=0;\n",
    "    firstHeader=soup.find('table')            #Finding header with table\n",
    "    for tag in [firstHeader] + firstHeader.findNextSiblings(): #Logic to parse data from the table and add the stock info to dictionary\n",
    "\n",
    "        if(tag.name==\"table\"):\n",
    "            i = i+1\n",
    "            for ntag_t in tag.findAll('td'):\n",
    "                if(ntag_t is not None):\n",
    "                    ntag_a = ntag_t.find('a')\n",
    "                    ntag_e = ntag_t.find('span')\n",
    "                    if ntag_a is not None and ntag_e is not None:\n",
    "                        str = ntag_a['href'].split(\"=\")\n",
    "                        expand = ntag_e['title']\n",
    "                        if(i==1):\n",
    "                            active_s_dict[str[1]]= expand.strip()  #Add associated symbol as key and name as Value int the dict\n",
    "                        elif (i==2):\n",
    "                            gainers_s_dict[str[1]]= expand.strip() #Add associated symbol as key and name as Value int the dict\n",
    "                        else:\n",
    "                            losers_s_dict[str[1]]= expand.strip()  #Add associated symbol as key and name as Value int the dict\n",
    "\n",
    "\n",
    "    csvdata = [] #Create Empty csvdata List to store all the stcok information\n",
    "    heading =[\"Category\",\"Symbol\",\"Name\",\"Open\",\"Close\",\"Volume\",\"MarketCap\"]\n",
    "    csvdata.append(heading) #Heading Info to print in the csv\n",
    "    \n",
    "    print(\"This is a program to scrape data from the https://money.cnn.com/data/hotstocks/ for a class project\")\n",
    "    print(\"Which stock are you interested in:\")\n",
    "    print(\" \")\n",
    "    print(\"Most Actives:\")\n",
    "    for x,y in active_s_dict.items(): #Loop through Each item in active dict\n",
    "        print (x,y)                   #Display Stock Symbol and Name\n",
    "        mytickerlist =[]\n",
    "        mytickerlist.append(x)\n",
    "        stock_app=[]\n",
    "\n",
    "        tickerurl ='https://finance.yahoo.com/quote/{myticker}?p={myticker}&.tsrc=fin-srch-v1'\n",
    "\n",
    "        for ticker in mytickerlist: #Take the Tickersymbol and query the Stock through yahoo finance website and store info\n",
    "\n",
    "            mystock_handle=requests.get(tickerurl.format(myticker =ticker))\n",
    "            mystock_text = mystock_handle.text\n",
    "            soup = BeautifulSoup(mystock_text, 'html.parser') #Use soup as html Parser\n",
    "            stock_app.append(\"Most Actives\")\n",
    "            stock_app.append(x)\n",
    "            stock_app.append(y)\n",
    "            #Look for attr open,close,volume and market cap to store the information\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'OPEN-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    stock_app.append(span.text.strip())\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'PREV_CLOSE-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    stock_app.append(span.text.strip())\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'TD_VOLUME-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    stock_app.append(span.text.strip())\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'MARKET_CAP-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    stock_app.append(span.text.strip())\n",
    "        csvdata.append(stock_app) #Add the data to csvlist\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Gainers:\")\n",
    "    for x,y in gainers_s_dict.items(): #Loop through Each item in Gainers dict\n",
    "        print (x,y)                    #Display Stock Symbol and Name\n",
    "        mytickerlist =[]\n",
    "        mytickerlist.append(x)\n",
    "        stock_app=[]\n",
    "\n",
    "        tickerurl ='https://finance.yahoo.com/quote/{myticker}?p={myticker}&.tsrc=fin-srch-v1'\n",
    "\n",
    "        for ticker in mytickerlist: #Take the Tickersymbol and query the Stock through yahoo finance website and store info\n",
    "\n",
    "            mystock_handle=requests.get(tickerurl.format(myticker =ticker))\n",
    "            mystock_text = mystock_handle.text\n",
    "            soup = BeautifulSoup(mystock_text, 'html.parser') #Use soup as html Parser\n",
    "            stock_app.append(\"Gainers\")\n",
    "            stock_app.append(x)\n",
    "            stock_app.append(y)\n",
    "            #Look for attr open,close,volume and market cap to store the information\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'OPEN-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    stock_app.append(span.text.strip())\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'PREV_CLOSE-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    stock_app.append(span.text.strip())\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'TD_VOLUME-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    stock_app.append(span.text.strip())\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'MARKET_CAP-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    stock_app.append(span.text.strip())\n",
    "        csvdata.append(stock_app) #Add the data to csvlist\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Losers:\")\n",
    "    for x,y in losers_s_dict.items(): #Loop through Each item in Losers dict\n",
    "        print (x,y)                   #Display Stock Symbol and Name\n",
    "        mytickerlist =[]\n",
    "        mytickerlist.append(x)\n",
    "        stock_app=[]\n",
    "\n",
    "        tickerurl ='https://finance.yahoo.com/quote/{myticker}?p={myticker}&.tsrc=fin-srch-v1'\n",
    "\n",
    "        for ticker in mytickerlist: #Take the Tickersymbol and query the Stock through yahoo finance website and store info\n",
    "\n",
    "            mystock_handle=requests.get(tickerurl.format(myticker =ticker))\n",
    "            mystock_text = mystock_handle.text\n",
    "            soup = BeautifulSoup(mystock_text, 'html.parser') #Use soup as html Parser\n",
    "            stock_app.append(\"Losers\")\n",
    "            stock_app.append(x)\n",
    "            stock_app.append(y)\n",
    "            #Look for attr open,close,volume and market cap to store the information\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'OPEN-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    stock_app.append(span.text.strip())\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'PREV_CLOSE-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    stock_app.append(span.text.strip())\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'TD_VOLUME-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    stock_app.append(span.text.strip())\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'MARKET_CAP-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    stock_app.append(span.text.strip())\n",
    "        csvdata.append(stock_app) #Add the data to csvlist\n",
    "\n",
    "    with open('stocks.csv', 'w') as csvFile: #Create a stocks.csv file for writing all the data\n",
    "        writer = csv.writer(csvFile)\n",
    "        writer.writerows(csvdata) #Write to the file all the data from csvdata list\n",
    "\n",
    "    print(\"\")\n",
    "    userin = input(\"User Inputs:\") #Prompt user to Enter the stock symbol interested in \n",
    "    print(\"\")\n",
    "    if userin in active_s_dict.keys(): #If the user Entered stock is present in active dict then display info\n",
    "        mytickerlist =[]\n",
    "        mytickerlist.append(userin.strip())\n",
    "        user_stock={}\n",
    "\n",
    "        tickerurl ='https://finance.yahoo.com/quote/{myticker}?p={myticker}&.tsrc=fin-srch-v1'\n",
    "\n",
    "        for ticker in mytickerlist: #Take the Tickersymbol and query the Stock through yahoo finance website and store info\n",
    "\n",
    "            mystock_handle=requests.get(tickerurl.format(myticker =ticker))\n",
    "            mystock_text = mystock_handle.text\n",
    "            soup = BeautifulSoup(mystock_text, 'html.parser') #Use soup as html Parser\n",
    "            #Look for attr open,close,volume and market cap to store the information\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'OPEN-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    user_stock['OPEN'] = span.text.strip()\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'PREV_CLOSE-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    user_stock['PREV_CLOSE'] = span.text.strip()\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'TD_VOLUME-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    user_stock['VOLUME'] = span.text.strip()\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'MARKET_CAP-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    user_stock['MARKET_CAP'] = span.text.strip()\n",
    "\n",
    "        print(\"The data for \"+userin+\" \"+active_s_dict[userin]+\" is the following:\")\n",
    "        print()\n",
    "        print(userin,active_s_dict[userin])\n",
    "        for x,y in user_stock.items(): #Print the Information for the user entered stock symbol\n",
    "            print (x,\":\",y)\n",
    "    elif userin in gainers_s_dict.keys():#If the user Entered stock is present in gainers dict then display info\n",
    "        mytickerlist =[]\n",
    "        mytickerlist.append(userin.strip())\n",
    "        user_stock={}\n",
    "\n",
    "        tickerurl ='https://finance.yahoo.com/quote/{myticker}?p={myticker}&.tsrc=fin-srch-v1'\n",
    "\n",
    "        for ticker in mytickerlist:\n",
    "\n",
    "            mystock_handle=requests.get(tickerurl.format(myticker =ticker))\n",
    "            mystock_text = mystock_handle.text\n",
    "            soup = BeautifulSoup(mystock_text, 'html.parser')#Use soup as html Parser\n",
    "            #Look for attr open,close,volume and market cap to store the information\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'OPEN-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    user_stock['OPEN'] = span.text.strip()\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'PREV_CLOSE-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    user_stock['PREV_CLOSE'] = span.text.strip()\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'TD_VOLUME-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    user_stock['VOLUME'] = span.text.strip()\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'MARKET_CAP-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    user_stock['MARKET_CAP'] = span.text.strip()\n",
    "\n",
    "        print(\"The data for \"+userin+\" \"+gainers_s_dict[userin]+\" is the following:\")\n",
    "        print()\n",
    "        print(userin,gainers_s_dict[userin])\n",
    "        for x,y in user_stock.items(): #Print the Information for the user entered stock symbol\n",
    "            print (x,\":\",y)\n",
    "    elif userin in losers_s_dict.keys():#If the user Entered stock is present in losers dict then display info\n",
    "        mytickerlist =[]\n",
    "        mytickerlist.append(userin.strip())\n",
    "        user_stock={}\n",
    "\n",
    "        tickerurl ='https://finance.yahoo.com/quote/{myticker}?p={myticker}&.tsrc=fin-srch-v1'\n",
    "\n",
    "        for ticker in mytickerlist:\n",
    "\n",
    "            mystock_handle=requests.get(tickerurl.format(myticker =ticker))\n",
    "            mystock_text = mystock_handle.text\n",
    "            soup = BeautifulSoup(mystock_text, 'html.parser') #Use soup as html Parser\n",
    "            #Look for attr open,close,volume and market cap to store the information\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'OPEN-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    user_stock['OPEN'] = span.text.strip()\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'PREV_CLOSE-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    user_stock['PREV_CLOSE'] = span.text.strip()\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'TD_VOLUME-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    user_stock['VOLUME'] = span.text.strip()\n",
    "            for td in soup.findAll('td', attrs={'data-test': 'MARKET_CAP-value'}):\n",
    "                for span in td.findAll('span', recursive=False):\n",
    "                    user_stock['MARKET_CAP'] = span.text.strip()\n",
    "\n",
    "        print(\"The data for \"+userin+\" \"+losers_s_dict[userin]+\" is the following:\")\n",
    "        print()\n",
    "        print(userin,losers_s_dict[userin])\n",
    "        for x,y in user_stock.items(): #Print the Information for the user entered stock symbol\n",
    "            print (x,\":\",y)\n",
    "    else: #If the User Entered stock symbol is not present in any of the dictionaries print appropriate message for user\n",
    "        print(\"Entered Stock is not available, please enter different stock from the list displayed\")\n",
    "    \n",
    "except requests.exceptions.RequestException as e: # Handle all the request  Exceptions \n",
    "    print(\"Check the website entered\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
